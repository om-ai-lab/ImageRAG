{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_bbox_widget import BBoxWidget\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple annotation workflow\n",
    "\n",
    "Let's say we have a folder of image files that we would like to create annotations for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_qs(line):    \n",
    "#     test_prompt = \"Select the best answer to the above multiple-choice question based on the image. Respond with only the letter (A, B, C, D, or E) of the correct option.\"\n",
    "#     qs = line[\"Text\"]\n",
    "#     choices = line['Answer choices']\n",
    "#     choice_prompt = ' The choices are listed below: \\n'\n",
    "#     for choice in choices:\n",
    "#         choice_prompt += choice + \"\\n\"\n",
    "#     qs += choice_prompt + test_prompt + '\\nThe best answer is:'\n",
    "#     return qs\n",
    "\n",
    "\n",
    "# def load_gt(line):    \n",
    "#     gt = line[\"Ground truth\"]\n",
    "#     return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fpath = \"/data1/zilun/ImageRAG0226/codebase/inference/MME-RealWorld-RS/MME-RealWorld-excludelite.json\"\n",
    "img_root = \"/data9/shz/dataset/MME-RealWorld/remote_sensing\"\n",
    "# deal_list = ['dota_v2_dota_v2_dota_v2_P4155.png', 'dota_v2_dota_v2_dota_v2_P8717.png', 'dota_v2_dota_v2_dota_v2_P5240.png', 'dota_v2_dota_v2_dota_v2_P8510.png', 'dota_v2_dota_v2_dota_v2_P6744.png', 'dota_v2_dota_v2_dota_v2_P9271.png', 'dota_v2_dota_v2_dota_v2_P10015.png', 'dota_v2_dota_v2_dota_v2_P3145.png', 'dota_v2_dota_v2_dota_v2_P8406.png', 'dota_v2_dota_v2_dota_v2_P6423.png', 'dota_v2_dota_v2_dota_v2_P6423.png', 'dota_v2_dota_v2_dota_v2_P6138.png']\n",
    "\n",
    "with open(json_fpath, 'r') as file:\n",
    "    questions = json.load(file)\n",
    "# questions = [question for question in questions if question[\"Image\"] in deal_list]\n",
    "img_paths = [line[\"Image\"] for line in questions]\n",
    "files = img_paths\n",
    "qs = [load_qs(line) for line in questions]\n",
    "gts = [load_gt(line) for line in questions]\n",
    "\n",
    "annotations = {}\n",
    "annotations_path = 'annotations_mmerealworld_exclude.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a progress bar to show how far we got\n",
    "w_progress = widgets.IntProgress(value=0, max=len(files), description='Progress')\n",
    "# the bbox widget\n",
    "w_bbox = BBoxWidget(\n",
    "    image = os.path.join(img_root, files[0]),\n",
    ")\n",
    "\n",
    "w_text = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Question and Ground Truth',\n",
    "    description='Info:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%', height='150px')  # Adjust the size of the text area\n",
    ")\n",
    "\n",
    "# combine widgets into a container\n",
    "w_container = widgets.VBox([\n",
    "    w_progress,\n",
    "    w_text,\n",
    "    w_bbox,\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when Skip button is pressed we move on to the next file\n",
    "@w_bbox.on_skip\n",
    "def skip():\n",
    "    w_progress.value += 1\n",
    "    if w_progress.value < len(files):\n",
    "        image_file = files[w_progress.value]\n",
    "        q = qs[w_progress.value]\n",
    "        gt = gts[w_progress.value]\n",
    "        w_bbox.image = os.path.join(img_root, image_file)\n",
    "        w_bbox.bboxes = []\n",
    "        w_text.value = f\"Question: {q}\\nGround Truth: {gt}\\nImage Name: {image_file}\"\n",
    "    else:\n",
    "        print(\"All images have been processed.\")\n",
    "\n",
    "@w_bbox.on_submit\n",
    "def submit():\n",
    "    qs = questions[w_progress.value][\"Question_id\"]\n",
    "    annotations[qs] = w_bbox.bboxes\n",
    "    with open(annotations_path, 'w') as f:\n",
    "        json.dump(annotations, f, indent=4)\n",
    "    skip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974857a3ea884e64a2f71b1a97bdb8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, description='Progress', max=3588), Textarea(value='', description='Info:',â€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qs(line):    \n",
    "    test_prompt = \"Select the best answer to the above multiple-choice question based on the image. Respond with only the letter (A, B, C, D, or E) of the correct option.\"\n",
    "    qs = line[\"Text\"]\n",
    "    choices = line['Answer choices']\n",
    "    choice_prompt = ' The choices are listed below: \\n'\n",
    "    for choice in choices:\n",
    "        choice_prompt += choice + \"\\n\"\n",
    "    qs += choice_prompt + test_prompt + '\\nThe best answer is:'\n",
    "    return qs\n",
    "\n",
    "\n",
    "def load_gt(line):    \n",
    "    gt = line[\"Ground truth\"]\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fpath = \"/data1/zilun/ImageRAG0226/codebase/inference/MME-RealWorld-RS/MME-RealWorld-excludelite.json\"\n",
    "img_root = \"/data9/shz/dataset/MME-RealWorld/remote_sensing\"\n",
    "with open(json_fpath, 'r') as file:\n",
    "    questions = json.load(file)\n",
    "questions = [question for question in questions if question[\"Subtask\"] == \"Remote Sensing\"]\n",
    "img_paths = [line[\"Image\"] for line in questions]\n",
    "files = img_paths\n",
    "qs = [load_qs(line) for line in questions]\n",
    "gts = [load_gt(line) for line in questions]\n",
    "\n",
    "annotations = {}\n",
    "annotations_path = 'annotations_mmerealworld_exclude.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a progress bar to show how far we got\n",
    "w_progress = widgets.IntProgress(value=0, max=len(files), description='Progress')\n",
    "# the bbox widget\n",
    "w_bbox = BBoxWidget(\n",
    "    image = os.path.join(img_root, files[0]),\n",
    ")\n",
    "\n",
    "w_text = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Question and Ground Truth',\n",
    "    description='Info:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%', height='150px')  # Adjust the size of the text area\n",
    ")\n",
    "\n",
    "# combine widgets into a container\n",
    "w_container = widgets.VBox([\n",
    "    w_progress,\n",
    "    w_text,\n",
    "    w_bbox,\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when Skip button is pressed we move on to the next file\n",
    "@w_bbox.on_skip\n",
    "def skip():\n",
    "    w_progress.value += 1\n",
    "    if w_progress.value < len(files):\n",
    "        image_file = files[w_progress.value]\n",
    "        q = qs[w_progress.value]\n",
    "        gt = gts[w_progress.value]\n",
    "        w_bbox.image = os.path.join(img_root, image_file)\n",
    "        w_bbox.bboxes = []\n",
    "        w_text.value = f\"Question: {q}\\nGround Truth: {gt}\\nImage Name: {image_file}\"\n",
    "    else:\n",
    "        print(\"All images have been processed.\")\n",
    "\n",
    "# when Submit button is pressed we save current annotations\n",
    "# and then move on to the next file\n",
    "@w_bbox.on_submit\n",
    "def submit():\n",
    "    image_file = files[w_progress.value]\n",
    "    # annotations[image_file] = [w_bbox.bboxes[0], w_bbox.bboxes[1], w_bbox.bboxes[0] + w_bbox.bboxes[2], w_bbox.bboxes[1] + w_bbox.bboxes[3]]\n",
    "    annotations[image_file] = w_bbox.bboxes\n",
    "    with open(annotations_path, 'w') as f:\n",
    "        json.dump(annotations, f, indent=4)\n",
    "    skip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
